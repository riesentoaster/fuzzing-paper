\documentclass{article}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[
    top=25mm,
    bottom=25mm,
    right=20mm,
    left=20mm
    ]{geometry}
\usepackage{longtable}
\usepackage{array}
\usepackage[style=ieee]{biblatex}
\addbibresource{sources.bib}
\usepackage{todonotes}
\usepackage{multicol}

\title{Looking at Challenges and Mitigation in Symbolic Execution Based Fuzzing Through the Lens of Survey Papers}
\author{Valentin Huber}
\begin{document}
\include{settings}

\maketitle

\todo{Abstract}

\tableofcontents
\pagebreak
\begin{multicols}{2}
    \section{Introduction}
    \begin{itemize}
        \item \textquote{Today, testing is the primary way to check the correctness of software. Billions of dollars are spent on testing in the software industry, as testing usually accounts for about 50\% of the cost of software development. It was recently estimated that software failures currently cost the US economy alone about \$60 billion every year, and that improvements in software testing infrastructure might save one-third of this cost.}\cite{DART}
        \item \textquote{The attack (WannaCry) startled the global economy by hitting its impact on around 230K–300K computers in about 150 countries, leading to an estimated substantial financial impact of US \$4–\$8 billion worldwide}\cite{Demystifying}
        \item \textquote{Software testing is the most commonly used technique for validating the quality of software, but it is typically a mostly manual process that accounts for a large fraction of software development and maintenance.}\cite{PreliminaryAssessment}
        \item Fuzzing is one of several software vulnerability techniques.\cite{VulnerabilityDiscoveryTechniques}
        \item \textquote{Compared with other techniques, fuzzing requires few knowledge of targets and could be easily scaled up to large applications, and thus has become the most popular vulnerability discovery solution, especially in the industry.}\cite{FuzzingASurvey}
        \item \textquote{The term “fuzz” was originally coined by Miller et al. in 1990 to refer to a program that “generates a stream of random characters to be consumed by a target program”\cite{UNIX}}\cite{ArtScienceEng}
        \item \textquote{There are many different dynamic analyses that can be described as “fuzzing.” A unifying feature of fuzzers is that they operate on, and produce, concrete inputs. Otherwise, fuzzers might be instantiated with many different design choices and many different parameter settings.}\cite{EvaluatingFuzzTesting}
        \item \textquote{Google could find 20K vulnerabilities in Chrome using fuzz testing}\cite{Demystifying}
        \item Fuzzing is used by lots of big players: Google, Microsoft, DoD, Cisco, Adobe all employ fuzzing as part of their secure development practices, and many of those have contributed to or written their own open-source or commercial fuzzers \cite{Demystifying}.
    \end{itemize}

    \section{Theoretical Principles}
    \begin{itemize}
        \item Program under test (PUT)
        \item Two approaches: Random mutation as described in \textit{An Empirical Study of the Reliability of UNIX Utilities} by Miller et al.\cite{UNIX} and pure symbolic execution, as introduced in \cite{Symbex}.
        \item The latter is infeasible for large programs and for any program that interacts with the environment, the former in its purest form is not very effective.
              \begin{itemize}
                  \item \textquote{A key disadvantage of classical symbolic execution is that it cannot generate an input if the symbolic path constraint along a feasible execution path contains formulas that cannot be (efficiently) solved by a constraint solver (for example, nonlinear constraints).}\cite{ReviewThreeDecades}
                  \item \textquote{The blackbox and whitebox strategies achieved similar results in all categories. This shows that, when testing applications with highly-structured inputs in a limited amount of time (2 hours), whitebox fuzzing, with the power of symbolic execution, does not improve much over simple blackbox fuzzing. In fact, in the code generator, those grammar-less strategies do not improve coverage much above the initial set of seed inputs.}\cite{GrammarBasedWhiteboxFuzzing}
              \end{itemize}
        \item Generally:
              \begin{itemize}
                  \item \textquote{The process begins by choosing a corpus of “seed” inputs with which to test the target program. The fuzzer then repeatedly mutates these inputs and evaluates the program under test. If the result produces “interesting” behavior, the fuzzer keeps the mutated input for future use and records what was observed. Eventually the fuzzer stops, either due to reaching a particular goal (e.g., finding a certain sort of bug) or reaching a timeout.}\cite{EvaluatingFuzzTesting}
                  \item \textquote{Different fuzzers record different observations when running the program under test. In a “black box” fuzzer, a single observation is made: whether the program crashed. In “gray box” fuzzing, observations also consist of intermediate information about the execution, for example, the branches taken during execution as determined by pairs of basic block identifiers executed directly in sequence. “White box” fuzzers can make observations and modifications by exploiting the semantics of application source (or binary) code, possibly involving sophisticated reasoning. Gathering additional observations adds overhead. Different fuzzers make different choices, hoping to trade higher overhead for better bug-finding effectiveness.}\cite{EvaluatingFuzzTesting}
                  \item \textquote{In any of these cases, the output from the fuzzer is some concrete input(s) and configurations that can be used from outside of the fuzzer to reproduce the observation. This allows software developers to confirm, reproduce, and debug issues.}\cite{EvaluatingFuzzTesting}
              \end{itemize}
        \item \textquote{Many of these tools also automatically find well-defined bugs, such as assertion errors, divisions by zero, NULL pointer dereferences, etc.}\cite{AllYouEverWanted}
    \end{itemize}


    \section{Related Works and Methods}
    \label{Methods}
    \begin{itemize}
        \item Large scientific body of work
        \item Review papers
              \begin{itemize}
                  \item Well cited
                  \item New
                  \item Specific topics to see if challenges and solutions differ
              \end{itemize}
        \item Gathered by
              \begin{itemize}
                  \item Search engines
                  \item Cited in review papers
                  \item Lists in review papers (as in \cite{Demystifying})
                  \item Cited in important primary papers
              \end{itemize}
    \end{itemize}

    \subsection{Survey Papers}
    \subsubsection{General Survey Papers}
    \begin{itemize}
        \item    Fuzzing: The State of the Art (\citedate{FuzzingTheStateOfTheArt})\cite{FuzzingTheStateOfTheArt}
        \item    An orchestrated survey of methodologies for automated software test case generation (\citedate{Orchestrated})\cite{Orchestrated}
        \item    A Survey of Symbolic Execution Techniques (\citedate{SurveySymbex})\cite{SurveySymbex}
        \item    A systematic review of fuzzing techniques (\citedate{Science})\cite{Science}
        \item    Fuzzing: State of the Art (\citedate{FuzzingStateOfTheArt2018})\cite{FuzzingStateOfTheArt2018}
        \item    Fuzzing: hack, art, and science (\citedate{HackArtScience})\cite{HackArtScience}
        \item    A Systematic Review of Search Strategies in Dynamic Symbolic Execution (\citedate{SearchStrategies})\cite{SearchStrategies}
        \item    A Survey of Hybrid Fuzzing based on Symbolic Execution (\citedate{SurveyHybrid})\cite{SurveyHybrid}
        \item    Fuzzing: Challenges and Reflections (\citedate{ChallengesAndReflections})\cite{ChallengesAndReflections}
        \item    Exploratory Review of Hybrid Fuzzing for Automated Vulnerability Detection (\citedate{Hybrid})\cite{Hybrid}
        \item    Fuzzing vulnerability discovery techniques: Survey, challenges and future directions (\citedate{FuzzingVulnerabilityDiscoveryTechniques})\cite{FuzzingVulnerabilityDiscoveryTechniques}
    \end{itemize}

    \paragraph{\papertitle{AllYouEverWanted}}
    Using a simple intermediate language (SIMPIL), this paper discusses taint analysis and forward symbolic execution, including examples and analysis of the theoretical foundations of symbolic execution. While fuzzing is mentioned in multiple instances, it is not the main focus. However, it still lists many of the drawbacks and advantages fuzzers based on symbolic execution have, and the additional perspective was valuable in assembling this review.

    \paragraph{\papertitle{PreliminaryAssessment}}
    After giving a short overview of issues faced by symbolic execution based fuzzers, this paper focuses on eight high impact fuzzing tools (JPF-SE and Symbolic (Java) PathFinder\cite{JPFSE, JavaPathFinder}, DART\cite{DART}, CUTE\cite{CUTE} and jCUTE\cite{ExplicitPathModelChecking}, CREST\cite{CREST}, SAGE\cite{SAGE}, Pex\cite{Pex}, EXE\cite{EXE}, and KLEE\cite{KLEE}).

    \paragraph{\papertitle{ReviewThreeDecades}}
    This survey paper, as the title suggests, focuses on symbolic execution. Starting with an explanation of classical symbolic execution, it then provides a list of issues that fuzzing tools based on symbolic execution face, along with attempts to mitigate those by adapting and extending the algorithms. Finally, the authors present five high-impact tools they worked on: DART\cite{DART}, CUTE\cite{CUTE}, CREST\cite{CREST}, EXE\cite{EXE}, and KLEE\cite{KLEE}.

    \paragraph{\papertitle{ReviewThreeDecades}}
    While not a classic survey paper, \textit{Evaluating Fuzz Testing} finds issues in how all 32 papers performed the evaluation of the system they introduced. It further proposes rules to follow to make an evaluation robust. Last, it contains a list of what advances each paper examined claims to introduce.

    \paragraph{\papertitle{FuzzingASurvey}}
    \citeauthor{FuzzingASurvey} focus on coverage-guided fuzzing, mentioning other approaches that can be mixed in and different applications it can be used for. They further categorize whitebox fuzzers in generation based fuzzers, mentioning SPIKE\cite{Spike} (whose website and source seems to no longer be available), Sulley\cite{Sulley} (with BooFuzz\cite{BooFuzz} as a currently maintained fork), and Peach\cite{Peach}, and mutation based fuzzers with the only mention being Miller\cite{Miller}. These are only mentioned, without any discussion. Last, they broadly discuss the challenges symbolic execution in fuzzing faces and, in an other section, present TaintScope\cite{TaintScope} and Driller\cite{Driller} as examples of using symbolic execution for specifically for path exploration.

    \paragraph{\papertitle{ArtScienceEng}}
    Starting with proposing a taxonomy for fuzzing itself and categorizing fuzzers, this paper proposes a general-purpose model of fuzzing, explaining the steps and approaches common fuzzers share. It further presents a genealogy, tracing the origins of important papers back to the work of \citeauthor*{UNIX}. However, it \textquote{does not provide a comprehensive survey on DSE}\cite{ArtScienceEng}, but only discusses whitebox fuzzing in a subsection and refers to other survey papers such as \cite{Orchestrated, AllYouEverWanted} for a more complete overview.

    \paragraph{\papertitle{FuzzingASurveyforRoadmap}}
    Similar to what is attempted in this paper, \citetitle{FuzzingASurveyforRoadmap} lists issues along common steps in fuzzing along with attempted solutions, but without the focus on symbolic execution. It does contain a short section about symbolic execution in the context input search space handling, but only discusses very few papers directly while often mentioning entire families of papers, with only some relying on symbolic execution.

    \paragraph{\papertitle{SystematicReview2023}}
    The authors of this paper guide the reader through advances in fuzzing along the works that introduced those. It includes a section about symbolic execution, which considers the following systems: Driller\cite{Driller}, QSYM\cite{QSYM}, SAVIOR\cite{SAVIOR}, DigFuzz\cite{DigFuzz}, Pangolin\cite{Pangolin}, and QuickFuzz\cite{QuickFuzz}.

    \paragraph{\papertitle{Demystifying}}
    This paper dedicates one of its chapter to first explaining the fundamental logic of symbolic execution, and then presenting three implementations (Driller\cite{Driller}, CONFETTI\cite{CONFETTI}, and FUZZOLIC\cite{FUZZOLIC}). It further investigates advances in IoT firmware and kernel fuzzers, but does not explain where up- and downsides of using symbolic execution in these domains lay.

    \subsubsection{Specific Survey Papers}
    \begin{itemize}
        \item    Network protocol fuzz testing for information systems and applications: a survey and taxonomy (\citedate{Network})\cite{Network}
        \item    A Survey of Dynamic Analysis and Test Generation for JavaScript (\citedate{JavaScript2})\cite{JavaScript2}
        \item    Fuzzing the Internet of Things: A Review on the Techniques and Challenges for Efficient Vulnerability Discovery in Embedded Systems (\citedate{IoT})\cite{IoT}
        \item    Firmware Fuzzing: The State of the Art (\citedate{Firmware})\cite{Firmware}
        \item    Research on Fuzzing Technology for JavaScript Engines (\citedate{JavaScript})\cite{JavaScript}
        \item    Ethereum Smart Contract Analysis Tools: A Systematic Review (\citedate{Ethereum})\cite{Ethereum}
        \item    Embedded fuzzing: a review of challenges, tools, and solutions (\citedate{Embedded2})\cite{Embedded2}
        \item    Fuzzing of Embedded Systems: A Survey (\citedate{Embedded})\cite{Embedded}
        \item    A Survey on the Development of Network Protocol Fuzzing Techniques (\citedate{Network2023})\cite{Network2023}
    \end{itemize}

    \section{Challenges and Mitigation}
    Heavily based on \cite{ReviewThreeDecades, PreliminaryAssessment}, extended based on information from all other information considered as listed in Section\ref{Methods}.

    \subsection{Impossible Constraints}
    \begin{itemize}
        \item \textquote{A key disadvantage of classical symbolic execution is that it cannot generate an input if the symbolic path constraint along a feasible execution path contains formulas that cannot be (efficiently) solved by a constraint solver (for example, nonlinear constraints).}\cite{ReviewThreeDecades}
        \item Two techniques that alleviate this problem:
              \begin{itemize}
                  \item Dynamic Symbolic Execution (DSE), or Concolic Testing (like DART\cite{DART} and its successor CUTE\cite{CUTE}, and CREST\cite{CREST}): Run concrete and symbolic execution at the same time, keep mapping between values, solve path constraint with one sub-constraint flipped to get input for an other path. \textquote{A key observation in DART is that imprecision in symbolic execution can be alleviated using concrete values and randomization}\cite{PreliminaryAssessment}
                  \item Execution-Generated Testing (EGT)\cite{EGT} (like EXE\cite{EXE} and KLEE\cite{KLEE}): Only execute symbolically if any operands are symbolic
              \end{itemize}
        \item These handle imprecision in symbex (like interaction with outside code (that is not instrumented for symbex), constraint solving timeouts, unhandled instructions (floating point), or system calls (\code{read}, interrupts, etc.)) by just using concrete values.
              \begin{itemize}
                  \item If none of the operands are symbolically, just use them
                  \item If any are, use the concrete values (direct in concolic, solution from path constraint in EGT)
              \end{itemize}
        \item Downside: missing some feasible paths, and therefore sacrificing completeness.
        \item Further Ideas: Special Constraint Solvers that improve floating point based constraint handling (like FloPSy\cite{FloPSy}) and complex mathematical constraints (like CORAL\cite{CORAL})
    \end{itemize}

    \subsection{System Calls}
    \begin{itemize}
        \item \textquote{Additionally, symbolic execution creates conflicts while handling system calls, since it does not support modeling all possible system calls and inter-process communication, such as pipes or sockets. Likewise, the non-deterministic behavior of system calls complicates the generation of inputs that consistently trigger specific paths.}\cite{Demystifying}
        \item HFL\cite{HFL} is a kernel fuzzer that heavily relies on symbolic execution. It lists three main issues the authors had to overcome: \textquote{(1) indirect control transfers determined by system call arguments (2) controlling and matching internal system state via system calls, and (3) nested argument type inference for invoking system calls}\cite{HFL}. To solve those issues, HFL \textquote{(1) converts implicit control transfers to explicit transfers, (2) infers system call sequence to build a consistent system state, and (3) identifies nested arguments types of system calls}\cite{HFL}.
    \end{itemize}

    \subsection{Environment Interaction}
    \begin{itemize}
        \item \textquote{[…KLEE's\cite{KLEE}] ability to handle interactions with the outside environment — e.g., with data read from the file system or over the network — by providing models designed to explore all possible legal interactions with the outside world.}\cite{PreliminaryAssessment}
    \end{itemize}

    \subsection{Path Explosion}
    Path Explosion: program path count usually exponential in the number of static branches in the code.
    \begin{itemize}
        \item Simple depth-first search, however this naïve approach gets stuck in non-terminating loops with symbolic conditions and is therefore rarely used. Both EXE\cite{EXE} and KLEE\cite{KLEE} can however be configured to run in this mode.
        \item Symbex inherently helps by only looking at possible branches. Example: EXE\cite{EXE} on \code{tcpdump}: only 42\% of instructions contained symbolic operands, less than 20\% of of symbolic branches have both sides feasible\cite{EXE}
        \item Prioritization of which path to explore next using heuristics (like statement or branch coverage (and using static analysis to guide), favouring statements that were run the fewest number of times, or random). Examples: EXE\cite{EXE}, SAGE\cite{SAGE}, CREST\cite{CREST}
              \begin{itemize}
                  \item Interleave random and symbolic execution. Examples: Hybrid Concolic Testing\cite{HCT, Driller, Cyberdyne}
                  \item Guide towards changes in a patch: Directed Incremental Symbolic Execution\cite{DiSE} and Directed Test Suite Augmentation\cite{DTSA}
                  \item Parallel state-space search algorithms like generational search (which generates multiple new inputs from a single symbolic execution): SAGE\cite{SAGE}, Eclipser\cite{Eclipser}
                  \item \textquote{CREST\cite{CREST} is an extensible platform for building and experimenting with heuristics for selecting which paths to explore}\cite{ReviewThreeDecades}
                  \item \textquote{we propose a novel approach called Fitnex, a search strategy that uses state-dependent fitness values (computed through a fitness function) to guide path exploration. The fitness function measures how close an already discovered feasible path is to a particular test target (e.g., covering a not-yet-covered branch)}\cite{Fitnex}
                  \item Let users select uninteresting parts of the code and avoid it (as in \cite{Chopped})
                  \item Weigh the approximate cost of executing a certain path against its demand, as done in QuickFuzz\cite{QuickFuzz}
                  \item Probabilistic approach: Use Monte Carlo path optimization to quantify the difficulty of each path using grey-box fuzzing to then let the white-box fuzzer focus on the paths that are believed to be most challenging for grey-box fuzzing to make progress.\cite{DigFuzz}
                  \item Guide execution towards code parts deemed to be interesting based on static analysis, such as pointer dereferences in loops as implemented in Dowser\cite{Dowser}, potential bugs according to UndefinedBehaviorSanitizer\cite{UndefinedBehaviorSanitizer} in SAVIOR\cite{SAVIOR} or more general prior static or dynamic program analysis such as in GRT\cite{GRT} or VUzzer\cite{VUzzer} to guide the symbolic execution engine.
              \end{itemize}
        \item Pruning redundant paths (\textquote{if a program path reaches the same program point with the same symbolic constraints as a previously explored path, then this path will continue to execute exactly the same from that point on and thus can be discarded.}\cite{RWset}) Eliminating redundant paths by analyzing the values read and written by the program.
        \item Sharing among states/copy on write: KLEE\cite{KLEE}
        \item Caching function summaries for later use by higher-level functions. Example: SMART\cite{SMART}
        \item Lazy test generation (as in LATEST\cite{LATEST})
        \item Static path merging (as in KLEE-FP\cite{KLEEFP})
        \item partial order and symmetry reductions (as in GSE\cite{GSE})
        \item Compact representation of path constraints (as in SAGE\cite{SAGE})
    \end{itemize}

    \subsection{Constraint Solving}
    \label{ConstraintSolving}
    Dominates runtime
    \begin{itemize}
        \item Irrelevant constraint elimination: Generally, we go from a solvable constraint set (namely the current execution with the solution being the current concrete values) to one where only one constraint changes (the one we flipped). Typically, major major parts of the constraint set are not influenced by the change and can be excluded from what is passed to the solver. We can then just use the values from the previous iteration. This is implemented, among others, in \cite{SAGE}.
        \item Identify independent sub-queries and solve them independently, as is done in EXE\cite{EXE} and KLEE\cite{KLEE}.
        \item Optimizing SMT queries before passing them to the solver. The optimization itself, however, can already be too complex to compute to employ this strategy effectively.
        \item Mocking and stubbing: Moles\cite{Moles}
        \item Incremental solving: Reuse the results of previous similar queries, because subsets of the constraints are still solved by the same results and supersets often do not invalidate existing solutions. (CUTE\cite{CUTE} and counterexample caching scheme in KLEE\cite{KLEE})
        \item Cache prior SMT query results and reuse them for future queries. Pangolin\cite{Pangolin} uses polyhedral path abstraction to replace query parts for more efficient models based on prior results.
        \item Improved SMT solvers (like Z3\cite{Z3} used in e.g. SAGE\cite{SAGE}, STP\cite{STP}, or cvc5\cite{CVC5} built during the development of EXE\cite{EXE})
        \item Intriguer\cite{Intriguer} uses taint analysis to discover instructions accessing a wide range of input bytes, and then performs symbolic execution for those instructions deemed important and only invoke the underlying SMT solver for complicated queries.
        \item Approximate SMT solvers, such as FUZZY-SAT implemented in FUZZOLOGIC\cite{FUZZOLIC}, or optimistic SMT solvers, as in QSYM\cite{QSYM}, generate interesting inputs based on a SMT query without relying on classic (and expensive) SMT solvers.
        \item Similarly, Eclipser\cite{Eclipser} uses instrumentation on the PUT to generate partial path conditions, which can then be solved without invoking SMT solvers to generate further inputs.
        \item Do not use intermediate representation (IR) to execute symbolically, but integrate the symbolic emulation with the native execution through dynamic binary translation, which prevents additional instructions (since often multiple RISC instructions are necessary to replace one CISC instruction), and allows finer-grained control over the constraint, thus making it smaller. Example: QSYM\cite{QSYM}
        \item SMT formulas can be transformed into programs, which in turn can then be solved using a coverage-guided fuzzer to generate solutions to the initial formula. JFI\cite{JFI} uses this technique to find solutions to floating-point constraints.
    \end{itemize}

    \subsection{Memory Modelling}
    Things like modelling \code{int}s as mathematical integers being imprecise since it ignores over-/underflows, and pointers being hard to deal with.
    \begin{itemize}
        \item Issue: Dereferencing symbolic pointer, as in pointer which can be influenced from the input.
              \begin{itemize}
                  \item \textquote{A sound strategy is to consider it a load from any possible satisfying assignment for the expression.}\cite{AllYouEverWanted}
                  \item \textquote{Symbolic memory addresses can lead to aliasing issues even along a single execution path. A potential address alias occurs when two memory operations refer to the same address.}\cite{AllYouEverWanted}
                  \item (Potentially) unsound assumptions: optionally rewrite all memory addresses as scalars based on name, like Vine\cite{BitBlaze}
                  \item Pass the dealiazing step to the SMT solver like CVC Lite\cite{CVCLite} or STP\cite{STP}.
                  \item Perform alias analysis. However, like in DART\cite{DART}, \textquote{part of the allure of forward symbolic execution is that it can be done at run-time}\cite{AllYouEverWanted}.
                  \item EXE\cite{EXE} and KLEE\cite{KLEE} \textquote{perform a mix of alias analyses and letting the SMT solver worry about aliasing}\cite{AllYouEverWanted}
                  \item Other systems like DART\cite{DART} and CUTE\cite{CUTE} cannot handle non-linear constraints and therefore cannot deal with symbolic references.
              \end{itemize}
        \item \textquote{On the one end of the spectrum is a system like DART\cite{DART} that only reasons about concrete pointers, or systems like CUTE\cite{CUTE} and CREST\cite{CREST} that support only equality and inequality constraints for pointers, which can be efficiently solved.\cite{CUTE} At the other end are systems like EXE\cite{EXE}, and more recently KLEE\cite{KLEE} and SAGE\cite{SAGE} that model pointers using the theory of arrays with selections and updates implemented by solvers like STP or Z3.}\cite{ReviewThreeDecades}
    \end{itemize}

    \subsection{Handling Concurrency}
    \begin{itemize}
        \item Testing usually difficult because of the inherent non-determinism.
        \item \textquote{Concolic testing was successfully combined with a variant of partial order reduction to test concurrent programs effectively.\cite{ScalableAutomatedMethods, OpenDistributedPrograms, ExplicitPathModelChecking,RaceDetection}}\cite{ReviewThreeDecades}
        \item \textquote{Generalized Symbolic Execution\cite{GSE} performs symbolic execution by leveraging an off-the-shelf model checker, whose built-in capabilities allow handling multi-threading (and other forms of non-determinism)}\cite{PreliminaryAssessment}
        \item \textquote{This method requires that a sequential version of the program be provided, to serve as the specification for the parallel one. The key idea is to use model checking, together with symbolic execution, to establish the equivalence of the two programs.}\cite{SPIN} (complex parallel numerical computations)
    \end{itemize}

    \subsection{Recursive Data Structures}
    \begin{itemize}
        \item \textquote{GSE handles input recursive data structures by using lazy initialization. GSE starts execution of the method on inputs with uninitialized fields and non-deterministically initializes fields when they are first ac- cessed during the method's symbolic execution.}\cite{PreliminaryAssessment}
        \item \textquote{Pex\cite{Pex} supports the generation of test inputs of primitive types as well as (recursive) complex data types, for which Pex automatically computes a factory method which creates an instance of a complex data type by invoking a constructor and a sequence of methods, whose parameters are also determined by Pex.}\cite{PreliminaryAssessment}
    \end{itemize}

    \subsection{Symbolic Jump Addresses}
    Symbolic target addresses of jump instructions are an obvious issue for symbolic execution based systems. Standard ways of handling these include:
    \begin{itemize}
        \item Concolic execution: Perform and trace the execution of a program under test, let it jump to the concrete address observed during this run, and finally perform symbolic execution on the trace. This leaves some potentially possible program states unexplored. Examples include CUTE\cite{CUTE}.
        \item Pass the reasoning issue to the SMT solver. This however makes the SMT queries more complicated and since constraint solving is already an issue in many cases (see Section\ref{ConstraintSolving}), this may not solve the issue after all.
        \item Use static analysis to locate possible jump targets.
    \end{itemize}

    \subsection{System Calls and OS Interactions}
    System calls (such as calls to \code{read} or interrupts) pose an obvious obstacle to pure symbolic execution, since they may introduce new symbolic variables or, more importantly, have side effects. This can be mitigated by manually creating summaries of these side effects (as done in EXE\cite{EXE} and KLEE\cite{KLEE}), or, again, employing concolic execution with all the upsides and drawbacks discussed before.

    \subsection{Selective Symbolic Execution}
    Not exhaustive.
    \begin{itemize}
        \item Tools like Driller\cite{Driller} perform classical fuzzing (in the case of Driller using AFL\cite{AFLPlusPlus}) until they are \textit{stuck}, meaning they are unable to produce inputs that discover additional paths. Driller then, and only then, invokes its concolic execution engine (Driller uses angr\cite{angr}) to trace the program under investigation executed with one of the previously generated inputs. Finally, it solves the resulting path constraints with one condition flipped to produce an input that will reach new parts of the software. Because Driller does not use symbolic execution for its primary discovery tool, it does not suffer from issues such as path explosion, because it only ever executes one path at a time using symbolic execution.
        \item By removing code blocks that are deemed irrelevant, T-FUZZ\cite{TFuzz} prevents its mutation-based fuzzer (which does not use symbolic execution) from getting stuck. It then employs symbolic execution to validate the bugs found.
        \item IFL\cite{IFL} generates quality input to a smart contract based on a symbolic execution engine and then uses them to train a neural network. This can then be used to fuzz other smart contracts since they often implement similar functionality.
        \item TaintScope\cite{TaintScope} uses taint analysis to bypass checksum checks and then symbolic execution to fix checksum fields in malformed test cases.
    \end{itemize}

    \section{Conclusions}
    \subsection{Future Work}
    \begin{itemize}
        \item Look at author overlap between the survey papers and influential primary papers to guide which review papers seem important (if you independently collect primary papers), if survey paper authors overemphasize their own contributions and maybe even miss other important developments
        \item History and composition of systems: Which influenced which, which builds on top of/extends which, etc.
    \end{itemize}

    \subsubsection{Bibliometry}

    \newpage
    \addcontentsline{toc}{section}{Bibliography}
    \printbibliography
\end{multicols}

\end{document}
